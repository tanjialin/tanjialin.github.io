<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>明月入怀</title>
    <link>https://www.tanjialin.cn/</link>
    
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>一切都是瞬间，一切都会过去</description>
    <pubDate>Thu, 29 Apr 2021 07:10:31 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>声学照相机</title>
      <link>https://www.tanjialin.cn/posts/38599.html</link>
      <guid>https://www.tanjialin.cn/posts/38599.html</guid>
      <pubDate>Wed, 28 Apr 2021 13:17:23 GMT</pubDate>
      <description>
      
        &lt;p&gt;利用传声器阵列测量一定范围内的声场分布的专用设备，可用于测量物体发出的声音的位置和声音辐射的状态，并用云图方式显示出直观的图像，即声成像测量&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>利用传声器阵列测量一定范围内的声场分布的专用设备，可用于测量物体发出的声音的位置和声音辐射的状态，并用云图方式显示出直观的图像，即声成像测量</p><a id="more"></a><p>本文完全自研，与任何项目无关联</p><h1 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h1><ol><li>时频图：直观展示声源频率成分，辅助用户分析判断异响类型</li><li>频率调整：可定位不同频率声源，通过调整频段过滤出特定频段的声音，有效排除环境干扰快速定位</li><li>定向拾音/定向抑制：在定位到声音异常的位置之后，增强该特定位置的声音，方便根据该声音的频率音调等特点推测异常的类型。同时可抑制其他方向的噪声干扰</li><li>分贝测量：可测量指定位置的分贝和距离，辅助判断声源情况</li><li>色带调节：调节热力图成像的分贝范围，可删减或扩大展示范围</li></ol><h1 id="麦克风设计"><a href="#麦克风设计" class="headerlink" title="麦克风设计"></a>麦克风设计</h1><h1 id="波束设计"><a href="#波束设计" class="headerlink" title="波束设计"></a>波束设计</h1><h1 id="算法设计"><a href="#算法设计" class="headerlink" title="算法设计"></a>算法设计</h1>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/38599.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>矩阵奇异值分解</title>
      <link>https://www.tanjialin.cn/posts/33822.html</link>
      <guid>https://www.tanjialin.cn/posts/33822.html</guid>
      <pubDate>Thu, 02 Apr 2020 17:07:24 GMT</pubDate>
      <description>
      
        &lt;p&gt;矩阵的奇异值分解（&lt;em&gt;singular value decomposition&lt;/em&gt;，简称SVD）是线性代数中很重要的内容，并且奇异值分解过程也是线性代数中相似对角化分解（也被称为特征值分解，&lt;em&gt;eigenvalue decomposition&lt;/em&gt;，简称EVD）的延伸。因此，以下将从线性代数中最基础的矩阵分解开始讲起，引出奇异值分解的定义，并最终给出奇异值分解的低秩逼近问题相关的证明过程。 &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>矩阵的奇异值分解（<em>singular value decomposition</em>，简称SVD）是线性代数中很重要的内容，并且奇异值分解过程也是线性代数中相似对角化分解（也被称为特征值分解，<em>eigenvalue decomposition</em>，简称EVD）的延伸。因此，以下将从线性代数中最基础的矩阵分解开始讲起，引出奇异值分解的定义，并最终给出奇异值分解的低秩逼近问题相关的证明过程。 </p><a id="more"></a>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/33822.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>5G Massive MIMO</title>
      <link>https://www.tanjialin.cn/posts/40627.html</link>
      <guid>https://www.tanjialin.cn/posts/40627.html</guid>
      <pubDate>Tue, 17 Mar 2020 13:54:36 GMT</pubDate>
      <description>
      
        &lt;p&gt;Massive MIMO（大规模天线技术，亦称为&lt;em&gt;Large Scale MIMO&lt;/em&gt;）是第五代移动通信（5G）中提高系统容量和频谱利用率的关键技术。此技术中，基站利用同一个时频域资源同时为多个终端进行服务，从而增强了基站同时接收和发送多路不同信号的能力，可以有效的提升频谱利用率、数据传输的稳定性和可靠性。 &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Massive MIMO（大规模天线技术，亦称为<em>Large Scale MIMO</em>）是第五代移动通信（5G）中提高系统容量和频谱利用率的关键技术。此技术中，基站利用同一个时频域资源同时为多个终端进行服务，从而增强了基站同时接收和发送多路不同信号的能力，可以有效的提升频谱利用率、数据传输的稳定性和可靠性。 </p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>原创文章，水平有限，如发现有错误，恳请及时联系作者修改，欢迎大家一起学习。 </p><p>本节作为引言，不讨论技术，只讨论当下实际中存在的一些问题，接下来会逐步更新Massive MIMO的部分关键技术。 </p><p>在LTE网络中，随着人们上网方式的改变，数据业务在近些年一直保持着爆炸性的增长，现有网络经常会出现支持不流畅的现象，但是在这样的情况下，仍然存在以下几个亟待解决的问题： </p><h3 id="移动视频的需求仍然在逐年增加"><a href="#移动视频的需求仍然在逐年增加" class="headerlink" title="移动视频的需求仍然在逐年增加"></a>移动视频的需求仍然在逐年增加</h3><p>这个问题是对峰值流量的一种挑战，可以考虑的方法包括：<strong>增大带宽</strong>；<strong>增加基站的密度</strong>；<strong>提高发射功率</strong>，这是比较不现实的，终端如果增加发射功率会导致电池电量的大量消耗，基站也存在同样问题，同时基站发射功率如果过大，会对邻区造成干扰；<strong>高Rank空分技术</strong>，现有的空分技术，波束之间的干扰比较大，导致不同终端的影响较大，从而降低了空分效率，如果引入高Rank空分技术，相互之间的干扰变小，类似很多辆车，并排行驶在泥泞的路上，尽管如果能安全通过，确实会比先后通过流量更高，但是效果并不明显，小心翼翼且易出事故，如果形成很多条互不干扰的路，就像立交桥一样，各自行驶，干扰极小，那么就极大的提升峰值流量。</p><h3 id="小区边缘用户体验差"><a href="#小区边缘用户体验差" class="headerlink" title="小区边缘用户体验差"></a>小区边缘用户体验差</h3><p>传统的4G宏站，从小区中心到小区边缘，业务速率会大幅度下滑，解决办法可以考虑如下：<strong>提高发射功率</strong>；<strong>新增站点补盲</strong>，这有悖于蜂窝网络的初衷，会大幅的提升组网费用；<strong>小区间干扰协调</strong>;<strong>波束赋形</strong>，传统的宽波束能量比较分散，作用距离相对较短，该方法可以通过使波束变窄，集中能量，则基站覆盖面积增大，如果能做到这一点，边缘用户的接收sinr会更高，体验也会得到明显提升，这种现象也可以类比相同功率的白炽灯、手电筒和激光笔，光束越窄，作用范围越大。</p><h3 id="垂直覆盖面临困难"><a href="#垂直覆盖面临困难" class="headerlink" title="垂直覆盖面临困难"></a>垂直覆盖面临困难</h3><p>传统4G宏站由于天线垂直波束过窄，架设天线时应着重考虑大多数的地面用户，天线高度不宜过高，所以无法为高层楼提供垂直的覆盖，造成高层楼信号较差。解决办法：<strong>提高基站架设高度</strong>;<strong>多组天线，分别覆盖</strong>;<strong>3D波束赋形</strong>，Massive MIMO 可在水平和垂直两个维度动态调整信号方向，使信号能量更集中、方向更精准，降低小区间的干扰，从而支持更多的用户在相同的时频资源上并行传输(空分复用)，从而达到提升小区吞吐量和边缘用户速率的效果。天线增益的提升，穿墙能力得到提升，实现了广度和深度的要求进行了有效的宽松。</p><p>此时，我们需要考虑，怎样才能有效提高信号的强度呢？提高信号强度，即提高接收到得信号功率，终端接收到的信号的信号功率大小表达式如下:</p><script type="math/tex; mode=display">{ P_ { rx } }  = \frac { { { P_ { tx } } } } { { 4\pi  { R^2 } } } \frac { { { \lambda ^2 } } } { { 4\pi } } { G_ { rx } } { G_ { tx } }</script><p>其中不能无限的增大发射功率${P_{tx}}$，不能缩短基站和手机之间的距离$R$，低频段资源又十分有限，很难将频带降低$\lambda$，所以无法增大波长，此时只能通过提升天线的数量，把两个天线增益参数${G_{rx}}$和${G_{tx}}$再次提升，进而提高接收功率。</p><p>5G采用了高频段，虽然高频信号的传播损耗非常大，但是由于高频段波长短，因此可以在有效的面积内部署更多的天线阵子，通过大规模天线阵列形成具有非常高增益的窄波束来抵消传播损失。这个特点对手机尤为重要，为其实现Massive MIMO奠定了一个非常好的基础。</p><p>Massive MIMO主要存在以下几点优势： </p><ul><li>天线波束变窄<br>传统的8天线，可以实现波束赋形，把不同用户放在不同的波束中，干扰较小；如果采用Massive MIMO,波束主瓣更窄，数量更多，相互之间干扰变小。</li><li><p>空分隔离更易</p></li><li><p>复用流数增多<br>流数越多，速率越高</p></li><li>小区容量提升<h2 id="关键技术"><a href="#关键技术" class="headerlink" title="关键技术"></a>关键技术</h2></li></ul><h3 id="波束赋形"><a href="#波束赋形" class="headerlink" title="波束赋形"></a>波束赋形</h3><p>波束赋形是指根据特定场景自适应的调整天线阵列的幅度图。此过程中，天线阵列会形成一个指向用户的波束，基站根据终端上行的信号来判断来波方向，进而改变下行波束的赋形权值，使波束跟随用户移动。而Massive MIMO是通过引入大量的天线，使天线阵列同一时间和频率资源满足空间上分离的多位用户的需求。</p><ul><li>提升小区边缘用户的接收信号质量</li></ul><ul><li>降低邻区的干扰<br>三维立体信号可以灵活的跟踪终端，而排除传统MIMO宽波束在跟踪终端的同时，由于宽波束对邻区产生干扰</li></ul><h3 id="高Rank空分技术"><a href="#高Rank空分技术" class="headerlink" title="高Rank空分技术"></a>高Rank空分技术</h3><ul><li><p>提升单用户峰值速率 </p></li><li><p>提升小区空分用户数量<br>相比传统LTE系统，支持更高阶的MU-MIMO，支持远超过8个用户同时传输数据</p></li><li>提升小区频谱效率<br>超过100根天线，相比传统8天线获得更高的空分复用增益，极大提高频谱利用效率</li><li>提升小区峰值速率 </li></ul><h3 id="3D波束赋形"><a href="#3D波束赋形" class="headerlink" title="3D波束赋形"></a>3D波束赋形</h3><p><strong>避免“灯下黑”问题</strong>： 在理论上，4G宏站正下方的辐射存在“灯下黑”现象，辐射水平应该是最低的，这是因为天线存在指向性，传播信号基本是以一定的下倾角水平方向发射，而不是垂直方向，下倾角越大，覆盖越小，反之覆盖面积就越大。所以基站之下的建筑恰好处于盲区，基站辐射最小，其接收的信号一般为远处基站的信号。基站辐射强度即基站信号强度，基站信号强度与手机的辐射强度密切相关，离基站越远，基站信号强度越弱，手机发射的功率会越大。</p><p>达成上述三项的关键在于预编码技术，后续将从技术角度分别介绍数字预编码技术和模拟预编码技术。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>暂无</p>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/40627.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>听觉系统</title>
      <link>https://www.tanjialin.cn/posts/23036.html</link>
      <guid>https://www.tanjialin.cn/posts/23036.html</guid>
      <pubDate>Sun, 01 Mar 2020 17:07:24 GMT</pubDate>
      <description>
      
        &lt;p&gt;人类听觉系统由听觉外周和听觉中枢两部分构成。听觉外周是一个声音传感器，它主要负责对声信号进行采集、处理并转换为神经刺激传递至听觉中枢。 &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>人类听觉系统由听觉外周和听觉中枢两部分构成。听觉外周是一个声音传感器，它主要负责对声信号进行采集、处理并转换为神经刺激传递至听觉中枢。 </p><a id="more"></a>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/23036.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>递归最小二乘</title>
      <link>https://www.tanjialin.cn/posts/44588.html</link>
      <guid>https://www.tanjialin.cn/posts/44588.html</guid>
      <pubDate>Sat, 08 Feb 2020 05:28:46 GMT</pubDate>
      <description>
      
        &lt;p&gt;最小二乘滤波算法的基本算法是递归最小二乘算法,这种算法实际上是FIR维纳滤波器的一种时间递归实现,它是严格以最小二乘准则为依据的算法。它的主要优点是收敛速度快,所以在快速信道均衡、实时系统辨识和时间序列分析中得到了广泛应用。其主要缺点是每次迭代需要的运算量很大。&lt;br&gt;&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>最小二乘滤波算法的基本算法是递归最小二乘算法,这种算法实际上是FIR维纳滤波器的一种时间递归实现,它是严格以最小二乘准则为依据的算法。它的主要优点是收敛速度快,所以在快速信道均衡、实时系统辨识和时间序列分析中得到了广泛应用。其主要缺点是每次迭代需要的运算量很大。<br><a id="more"></a></p><h1 id="RLS原理"><a href="#RLS原理" class="headerlink" title="RLS原理"></a>RLS原理</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>考虑指数加权的优化问题：</p><script type="math/tex; mode=display">\min J_{n}(\boldsymbol{w})=\sum_{i=0}^{n} \lambda^{n-i}|e(i)|^{2}=\sum_{i=0}^{n} \lambda^{n-i}\left|y(i)-\boldsymbol{w}^{\mathrm{H}}(n) \boldsymbol{x}(i)\right|^{2}</script><p>$0&lt;\lambda \leq 1$为遗忘因子，这里只讨论平稳情况，取$\lambda=1$</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial J_{n}(\boldsymbol{w})}{\partial \boldsymbol{w}^{*}(n)}=& \frac{\partial}{\partial \boldsymbol{w}^{*}(n)} \sum_{i=1}^{n} \lambda^{n-i}\left[y(i)-\boldsymbol{w}^{\mathrm{H}}(n) \boldsymbol{x}(i)\right] \\& \times\left[y(i)-\boldsymbol{w}^{\mathrm{H}}(n) \boldsymbol{x}(i)\right]^{*} \\=& \boldsymbol{R}(n) \boldsymbol{w}(n)-\boldsymbol{r}(n)\end{aligned}</script><p>从而得到最优解：</p><script type="math/tex; mode=display">\boldsymbol{w}_{\mathrm{opt}}(n)=\boldsymbol{R}^{-1}(n) \boldsymbol{r}(n)</script><p>其中：</p><script type="math/tex; mode=display">\boldsymbol{R}(n)=\sum_{i=0}^{n} \lambda^{n-i} \boldsymbol{x}(i) \boldsymbol{x}^{\mathrm{H}}(i), \quad \boldsymbol{r}(n)=\sum_{i=0}^{n} \lambda^{n-i} \boldsymbol{x}(i) y^{*}(i)</script><p>可以看到，$\lambda=1$对应的就是最小二乘思想。回头看看之前分析的LMS以及NLMS，用的是随机梯度下降的思想，这是RLS与LMS很明显的不同点。<br>由于$x(i)$、$y(i)$时刻在变换，最优解如何更新呢？</p><h2 id="迭代更新"><a href="#迭代更新" class="headerlink" title="迭代更新"></a>迭代更新</h2><p>矩阵求逆引理：<br>设A和B是两个M*M正定阵，它们之间的关系为：</p><script type="math/tex; mode=display">\mathbf{A}=\mathbf{B}^{-1}+\mathbf{C D}^{-1} \mathbf{C}^{H}</script><p>其中，D是N<em>M正定阵，C是M</em>N矩阵。根据矩阵求逆引理，可将A的逆矩阵表示为：</p><script type="math/tex; mode=display">\mathbf{A}^{-1}=\mathbf{B}-\mathbf{B C}\left(\mathbf{D}+\mathbf{C}^{H} \mathbf{B C}\right)^{-1} \mathbf{C}^{H} \mathbf{B}</script><p>定义逆矩阵：</p><script type="math/tex; mode=display">\boldsymbol{P}(n)=\boldsymbol{R}^{-1}(n)</script><p>利用逆阵求逆引理：</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{P}(n) &=\frac{1}{\lambda}\left[\boldsymbol{P}(n-1)-\frac{\boldsymbol{P}(n-1) \boldsymbol{x}(n) \boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1)}{\lambda+\boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1) \boldsymbol{x}(n)}\right] \\&=\frac{1}{\lambda}\left[\boldsymbol{P}(n-1)-k(n) \boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1)\right]\end{aligned}</script><p>其中$k(n)$称为<strong>增益向量</strong>，由上式得出：</p><script type="math/tex; mode=display">\boldsymbol{k}(n)=\frac{\boldsymbol{P}(n-1) \boldsymbol{x}(n)}{\lambda+\boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1) \boldsymbol{x}(n)}</script><p>借助迭代：</p><script type="math/tex; mode=display">\boldsymbol{R}(n)=\lambda \boldsymbol{R}(n-1)+\boldsymbol{x}(n) \boldsymbol{x}^{\mathrm{H}}(n)</script><script type="math/tex; mode=display">\boldsymbol{r}(n)=\lambda \boldsymbol{r}(n-1)+\boldsymbol{x}(n) y^{*}(n)</script><p>可以得到权重的更新公式：</p><script type="math/tex; mode=display">\boldsymbol{w}(n)=\boldsymbol{w}(n-1)+\boldsymbol{k}(n) \varepsilon^{*}(n)</script><p>其中$\varepsilon(n)$为估计误差：</p><script type="math/tex; mode=display">\epsilon(n)=y(n)-\boldsymbol{w}^{\mathrm{H}}(n-1) \boldsymbol{x}(n)</script><p>至此实现RLS的整个步骤。</p><h1 id="RLS应用实例"><a href="#RLS应用实例" class="headerlink" title="RLS应用实例"></a>RLS应用实例</h1><h2 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h2><p>结合上文的推导，给出RLS的迭代步骤：</p><ol><li>初始化<script type="math/tex; mode=display">\boldsymbol{w}(0)=\mathbf{0}, \boldsymbol{P}(0)=\delta^{-1} \boldsymbol{I} \quad(0<\delta \ll 1)</script>其中$\delta$为很小的正数，如1e-7；</li><li>迭代更新<script type="math/tex; mode=display">\begin{array}{l}\varepsilon(n)=y(n)-\boldsymbol{w}^{\mathrm{H}}(n-1) \boldsymbol{x}(n) \\\boldsymbol{k}(n)=\frac{\boldsymbol{P}(n-1) \boldsymbol{x}(n)}{\lambda+\boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1) \boldsymbol{x}(n)} \\\boldsymbol{P}(n)=\frac{1}{\lambda}\left[\boldsymbol{P}(n-1)-\boldsymbol{k}(n) \boldsymbol{x}^{\mathrm{H}}(n) \boldsymbol{P}(n-1)\right] \\\boldsymbol{w}(n)=\boldsymbol{w}(n-1)+\boldsymbol{k}(n) \varepsilon^{*}(n)\end{array}</script></li></ol><h2 id="代码应用"><a href="#代码应用" class="headerlink" title="代码应用"></a>代码应用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">function [e,w]&#x3D;rls(lambda,M,u,d,delta)</span><br><span class="line">% recursive least squares,rls.</span><br><span class="line">w&#x3D;zeros(M,1);</span><br><span class="line">P&#x3D;eye(M)&#x2F;delta;</span><br><span class="line">u&#x3D;u(:);</span><br><span class="line">d&#x3D;d(:);</span><br><span class="line">% input signal length</span><br><span class="line">N&#x3D;length(u);</span><br><span class="line">% error vector</span><br><span class="line">e&#x3D;d.&#39;;</span><br><span class="line">% Step2: Loop, RLS</span><br><span class="line">for n&#x3D;M:N</span><br><span class="line">    uvec&#x3D;u(n:-1:n-M+1);</span><br><span class="line">    e(n)&#x3D;d(n)-w&#39;*uvec;</span><br><span class="line">    k&#x3D;lambda^(-1)*P*uvec&#x2F;(1+lambda^(-1)*uvec&#39;*P*uvec);</span><br><span class="line">    P&#x3D;lambda^(-1)*P-lambda^(-1)*k*uvec&#39;*P;</span><br><span class="line">    w&#x3D;w+k*conj(e(n));</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>应用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[s, fs, bits] &#x3D; wavread(filename);         </span><br><span class="line">s&#x3D;s-mean(s);                          </span><br><span class="line">s&#x3D;s&#x2F;max(abs(s));                      </span><br><span class="line">N&#x3D;length(s);                           </span><br><span class="line">time&#x3D;(0:N-1)&#x2F;fs;                      </span><br><span class="line">clean&#x3D;s&#39;;</span><br><span class="line">ref_noise&#x3D;.1*randn(1,length(s));</span><br><span class="line">mixed &#x3D; clean+ref_noise;</span><br><span class="line">mu&#x3D;0.05;M&#x3D;2;espon&#x3D;1e-4;</span><br><span class="line">% [en,wn,yn]&#x3D;lmsFunc(mu,M,ref_noise,mixed);</span><br><span class="line">% [en,wn,yn]&#x3D;nlmsFunc(mu,M,ref_noise,mixed,espon);</span><br><span class="line">delta &#x3D; 1e-7;</span><br><span class="line">lambda &#x3D; 1;</span><br><span class="line">[en,w]&#x3D;rls(lambda,M,ref_noise,mixed,delta);</span><br></pre></td></tr></table></figure><br>对应结果图：<br><img src="/images/RLS.png" alt="img"><br>可以看出不像NLMS/LMS有一个慢速收敛的过程，RLS在开始阶段就得到较好的降噪。</p><h2 id="对比LMS"><a href="#对比LMS" class="headerlink" title="对比LMS"></a>对比LMS</h2><p>与LMS对比，可以观察到RLS的几点特性：</p><ul><li>平稳环境λ=1，其实是最小二乘的思想；LMS/NLMS是随机梯度下降思想；</li><li>最小二乘是直接得出结果，随机梯度下降收敛慢，因此RLS比LMS/NLMS收敛快一个数量级；</li></ul>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/44588.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>稳健矢量最优化自适应波束形成</title>
      <link>https://www.tanjialin.cn/posts/57993.html</link>
      <guid>https://www.tanjialin.cn/posts/57993.html</guid>
      <pubDate>Sun, 17 Nov 2019 11:56:34 GMT</pubDate>
      <description>
      
        &lt;p&gt;在提高算法稳健性时，会用到不同的准则作为优化准则，将这些算法统一到一个框架下，本文构造了矢量最优化稳健波束形成方法，并通过二阶锥规划理论方法进行求解，分析各个参数对最优权矢量的影响，并推导自适应权矢量的近似表达式。&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>在提高算法稳健性时，会用到不同的准则作为优化准则，将这些算法统一到一个框架下，本文构造了矢量最优化稳健波束形成方法，并通过二阶锥规划理论方法进行求解，分析各个参数对最优权矢量的影响，并推导自适应权矢量的近似表达式。</p><a id="more"></a>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/57993.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>最小二乘法</title>
      <link>https://www.tanjialin.cn/posts/53030.html</link>
      <guid>https://www.tanjialin.cn/posts/53030.html</guid>
      <pubDate>Mon, 21 Oct 2019 11:38:27 GMT</pubDate>
      <description>
      
        &lt;p&gt;最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。</p><a id="more"></a><h1 id="矩阵方程问题描述"><a href="#矩阵方程问题描述" class="headerlink" title="矩阵方程问题描述"></a>矩阵方程问题描述</h1><h2 id="基本问题描述"><a href="#基本问题描述" class="headerlink" title="基本问题描述"></a>基本问题描述</h2><p>许多问题可以建模为矩阵方程形式：</p><script type="math/tex; mode=display">\mathbf{A} \mathbf{x}=\mathbf{b}</script><p>其中根据向量$\mathbf{b} \in \mathbb{R}^{m \times 1}$ 和矩阵$\mathbf{A} \in \mathbb{R}^{m \times n}$的不同，矩阵方程的求解主要分为以下三类问题：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 超定矩阵方程 </span><br><span class="line">m &gt; n，b和A均已知，其中之一或二者可能存在观测误差、干扰；</span><br><span class="line">2. 盲矩阵方程</span><br><span class="line">仅向量b已知，矩阵A未知；</span><br><span class="line">3. 欠定稀疏矩阵方程</span><br><span class="line">m &lt; n，b和A均已知。</span><br></pre></td></tr></table></figure><p>每一类问题，都有对应的方法：如对于<strong>超定矩阵方程</strong>，观测结果足够多，方程个数大于未知数个数，对应矩阵<strong>通常</strong>列满秩（不绝对），可以利用最小二乘得到唯一确定解；对于<strong>欠定矩阵方程</strong>，方程个数小于未知数个数，得出的解有多种可能，所以通常需要添加约束——例如稀疏性，虽然解有多种，最稀疏的可能只用一种，这要就得到了唯一确定解。给出问题与对应求解的示意图：</p><p><img src="/images/LS.png" alt="Capon波束形成空间谱"></p><p>对于欠定稀疏矩阵求解，核心问题为：</p><script type="math/tex; mode=display">\min _{x}\|\mathbf{x}\|_{0} \quad \text { s.t. } \quad \mathbf{A x}=\mathbf{b}</script><p>这也是稀疏表示和压缩感知的核心问题，由于不免带有噪声，问题通常松弛为：</p><script type="math/tex; mode=display">\min _{x}\|\mathbf{x}\|_{0} \quad \text { s.t. } \quad\|\mathbf{A} \mathbf{x}-\mathbf{b}\|_{2} \leq \varepsilon</script><h2 id="最小二乘问题"><a href="#最小二乘问题" class="headerlink" title="最小二乘问题"></a>最小二乘问题</h2><p>最小二乘根据噪声类型的不同，可以分为：普通最小二乘、数据最小二乘、总体最小二乘。</p><ul><li>普通最小二乘(<em>Ordinary least squares,OLS</em>)<br>此时，向量b(观测向量)带有误差，对应的问题为：<script type="math/tex; mode=display">\mathbf{A} \mathbf{x}=\mathbf{b}+\Delta \mathbf{b} \Rightarrow \mathbf{A} \mathbf{x}=\mathbf{b}_{0}</script></li><li>数据最小二乘(<em>Data least squares,DLS</em>)<br>此时，数据矩阵A带有误差，对应的问题是：<script type="math/tex; mode=display">(\mathbf{A}+\Delta \mathbf{A}) \mathbf{x}=\mathbf{b} \Rightarrow \mathbf{A} \mathbf{x}_{0}=\mathbf{b}</script></li><li>总体最小二乘(<em>Total least squares,TLS</em>)<br>此时，数据矩阵A和数据矩阵A都带有误差，对应的问题是：<script type="math/tex; mode=display">(\mathbf{A}+\Delta \mathbf{A}) \mathbf{x}=\mathbf{b}+\Delta \mathbf{b} \Rightarrow \mathbf{A} \mathbf{x}_{0}=\mathbf{b}_{0}</script>本文<strong>仅分析超定方程情况</strong>，且只讨论<strong>普通最小二乘问题</strong>。</li></ul><h1 id="普通最小二乘求解"><a href="#普通最小二乘求解" class="headerlink" title="普通最小二乘求解"></a>普通最小二乘求解</h1><p>问题描述：</p><script type="math/tex; mode=display">\min _{x}\|\Delta \mathbf{b}\|^{2}=\min _{x}(\mathbf{A} \mathbf{x}-\mathbf{b})^{T}(\mathbf{A} \mathbf{x}-\mathbf{b})</script><p>其偏导为：</p><script type="math/tex; mode=display">\mathbf{A}^{T} \mathbf{A} \mathbf{x}=\mathbf{A}^{T} \mathbf{b}</script><p>case1：列满秩，$\operatorname{rank}((\mathbf{A}))=n$<br>此时$\left(\mathbf{A}^{T} \mathbf{A}\right)$可逆，对应的解唯一，从而有：</p><script type="math/tex; mode=display">\mathbf{x}_{O L S}=\left(\mathbf{A}^{T} \mathbf{A}\right)^{-1} \mathbf{A}^{T} \mathbf{b}</script><p>case2：秩亏缺，$\operatorname{rank}((\mathbf{A}))&lt;n$<br>这种情况下，需要借助Moore-Penrose进行广义逆求解，从而有：</p><script type="math/tex; mode=display">\mathbf{x}_{O L S}=\left(\mathbf{A}^{T} \mathbf{A}\right)^{\dagger} \mathbf{A}^{T} \mathbf{b}</script><p><strong>秩亏缺情况下，得到的解不再是唯一的，但基于Moore-Penrose的解是唯一的</strong>，这就不免有一个问题——它是增加了何种约束？这里直接给出结论：此时的解为最小范数最小二乘解(<em>minimum norm least squares solution</em>)，或者说此时向量对应欧式距离最短.</p><h1 id="普通最小二乘与最大似然"><a href="#普通最小二乘与最大似然" class="headerlink" title="普通最小二乘与最大似然"></a>普通最小二乘与最大似然</h1><p>给出数学模型（以多项式拟合为例，N次拟合，共M组样本点）：</p><script type="math/tex; mode=display">\left\{\begin{array}{l}a_{0}+a_{1} x_{1}+a_{2} x_{1}^{2}+\ldots a_{N} x_{1}^{N}-y_{1}=\varepsilon_{1} \\a_{0}+a_{1} x_{2}+a_{2} x_{2}^{2}+\ldots a_{N} x_{2}^{N}-y_{2}=\varepsilon_{2} \\\cdots \\a_{0}+a_{1} x_{M}+a_{2} x_{M}^{2}+\ldots a_{N} x_{M}^{N}-y_{M}=\varepsilon_{M}\end{array}\right.</script><p>普通最小二乘准则函数：</p><script type="math/tex; mode=display">J_{1}=\sum_{i=1}^{M}\left|f\left(x_{i}\right)-y_{i}\right|^{2}=\sum_{i=1}^{M}\left|\varepsilon_{i}\right|^{2}</script><p>最大似然准则：</p><p>假设误差均服从$\left(0, \delta^{2}\right)$的正态分布，则有似然函数：</p><script type="math/tex; mode=display">L_{2}=\frac{1}{\sqrt{2 \pi} \delta} e^{-\frac{\varepsilon_{1}^{2}}{2 \delta^{2}}} \cdot \frac{1}{\sqrt{2 \pi} \delta} e^{-\frac{\varepsilon_{2}^{2}}{2 \delta^{2}}} \ldots \cdot \frac{1}{\sqrt{2 \pi} \delta} e^{-\frac{\varepsilon_{M}^{2}}{2 \delta^{2}}}</script><p>求对数之后，最大似然准则函数等价于：</p><script type="math/tex; mode=display">J_{2}=\sum_{i=1}^{M}\left|\varepsilon_{i}^{2}\right|=\sum_{i=1}^{M}\left|\varepsilon_{i}\right|^{2}</script><p>二者等价。</p><h1 id="最小二乘与梯度下降"><a href="#最小二乘与梯度下降" class="headerlink" title="最小二乘与梯度下降"></a>最小二乘与梯度下降</h1><p>上文一个大前提就是方程可以转化为线性变换：</p><script type="math/tex; mode=display">\mathbf{A} \mathbf{x}=\mathbf{b}</script><p>但很多时候不能实现问题的转化，非线性没有闭式解，这个时候仍然可以借助梯度下降求解，梯度下降在前文有分析。梯度下降是迭代的方式去逼近最优解，虽然可能是局部最优；而最小二乘是利用矩阵的形式直接得出结果。</p>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/53030.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>最小均方误差滤波器</title>
      <link>https://www.tanjialin.cn/posts/18684.html</link>
      <guid>https://www.tanjialin.cn/posts/18684.html</guid>
      <pubDate>Wed, 09 Oct 2019 07:18:02 GMT</pubDate>
      <description>
      
      </description>
      
      
      <comments>https://www.tanjialin.cn/posts/18684.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>梯度下降算法</title>
      <link>https://www.tanjialin.cn/posts/12524.html</link>
      <guid>https://www.tanjialin.cn/posts/12524.html</guid>
      <pubDate>Mon, 16 Sep 2019 09:17:23 GMT</pubDate>
      <description>
      
        &lt;p&gt;梯度下降算法的解释：梯度下降算法最速下降法又称为梯度法，它是解析法中最古老的一种，其他解析方法或是它的变形，或是受它的启发而得到的，因此它是最优化方法的基础。作为一种基本的算法，他在最优化方法中占有重要地位。&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>梯度下降算法的解释：梯度下降算法最速下降法又称为梯度法，它是解析法中最古老的一种，其他解析方法或是它的变形，或是受它的启发而得到的，因此它是最优化方法的基础。作为一种基本的算法，他在最优化方法中占有重要地位。</p><a id="more"></a>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/12524.html#disqus_thread</comments>
    </item>
    
    <item>
      <title>MATLAB按数字顺序读取文件</title>
      <link>https://www.tanjialin.cn/posts/12218.html</link>
      <guid>https://www.tanjialin.cn/posts/12218.html</guid>
      <pubDate>Mon, 02 Sep 2019 12:27:19 GMT</pubDate>
      <description>
      
        &lt;p&gt;最近手上一个项目需要生成一个超大文件，但是内存不够需要在超算分散运行，生成了大量的散碎文件最终需要拼凑，以下代码可以将文件按自然数顺序排序，并且将矩阵在第三维度进行拼凑&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>最近手上一个项目需要生成一个超大文件，但是内存不够需要在超算分散运行，生成了大量的散碎文件最终需要拼凑，以下代码可以将文件按自然数顺序排序，并且将矩阵在第三维度进行拼凑</p><a id="more"></a><h2 id="MATLAB按数字顺序读取文件"><a href="#MATLAB按数字顺序读取文件" class="headerlink" title="MATLAB按数字顺序读取文件"></a>MATLAB按数字顺序读取文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">clc</span><br><span class="line">clear all</span><br><span class="line"></span><br><span class="line">dbstop if error</span><br><span class="line"></span><br><span class="line">trainPath&#x3D;&#39;E:\project\16面阵\file7\&#39;;  </span><br><span class="line">train  &#x3D; dir([trainPath &#39;*.mat&#39;]);</span><br><span class="line">train_num &#x3D; length(train);</span><br><span class="line">data_all&#x3D;[];</span><br><span class="line"></span><br><span class="line">sort_nat_name&#x3D;sort_mat(&#123;train.name&#125;);   </span><br><span class="line"> </span><br><span class="line">for i&#x3D;1:train_num</span><br><span class="line">  data &#x3D; load(sort_nat_name&#123;i&#125;); </span><br><span class="line">  data_matx &#x3D; cell2mat(struct2cell(data));</span><br><span class="line">  if i &#x3D;&#x3D; 1</span><br><span class="line">      data_all(:,:,size(data_all,3):size(data_matx,3)) &#x3D; data_matx;   </span><br><span class="line">  else</span><br><span class="line">      data_all(:,:,size(data_all,3) + 1:size(data_all,3)+size(data_matx,3)) &#x3D; data_matx;</span><br><span class="line">  end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function [cs,index] &#x3D; sort_mat(c,mode)</span><br><span class="line"></span><br><span class="line">if nargin &lt; 2</span><br><span class="line">    mode &#x3D; &#39;ascend&#39;;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">modes &#x3D; strcmpi(mode,&#123;&#39;ascend&#39;,&#39;descend&#39;&#125;);</span><br><span class="line">is_descend &#x3D; modes(2);</span><br><span class="line">if ~any(modes)</span><br><span class="line">    error(&#39;sort_nat:sortDirection&#39;,...</span><br><span class="line">        &#39;sorting direction must be &#39;&#39;ascend&#39;&#39; or &#39;&#39;descend&#39;&#39;.&#39;)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">c2 &#x3D; regexprep(c,&#39;\d+&#39;,&#39;0&#39;);</span><br><span class="line"></span><br><span class="line">s1 &#x3D; char(c2);</span><br><span class="line">z &#x3D; s1 &#x3D;&#x3D; &#39;0&#39;;</span><br><span class="line"></span><br><span class="line">[digruns,first,last] &#x3D; regexp(c,&#39;\d+&#39;,&#39;match&#39;,&#39;start&#39;,&#39;end&#39;);</span><br><span class="line"></span><br><span class="line">num_str &#x3D; length(c);</span><br><span class="line">max_len &#x3D; size(s1,2);</span><br><span class="line">num_val &#x3D; NaN(num_str,max_len);</span><br><span class="line">num_dig &#x3D; NaN(num_str,max_len);</span><br><span class="line">for i &#x3D; 1:num_str</span><br><span class="line">    num_val(i,z(i,:)) &#x3D; sscanf(sprintf(&#39;%s &#39;,digruns&#123;i&#125;&#123;:&#125;),&#39;%f&#39;);</span><br><span class="line">    num_dig(i,z(i,:)) &#x3D; last&#123;i&#125; - first&#123;i&#125; + 1;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">activecols &#x3D; reshape(find(~all(isnan(num_val))),1,[]);</span><br><span class="line">n &#x3D; length(activecols);</span><br><span class="line"></span><br><span class="line">numcols &#x3D; activecols + (1:2:2*n);</span><br><span class="line"></span><br><span class="line">ndigcols &#x3D; numcols + 1;</span><br><span class="line"></span><br><span class="line">charcols &#x3D; true(1,max_len + 2*n);</span><br><span class="line">charcols(numcols) &#x3D; false;</span><br><span class="line">charcols(ndigcols) &#x3D; false;</span><br><span class="line"></span><br><span class="line">comp &#x3D; zeros(num_str,max_len + 2*n);</span><br><span class="line">comp(:,charcols) &#x3D; double(s1);</span><br><span class="line">comp(:,numcols) &#x3D; num_val(:,activecols);</span><br><span class="line">comp(:,ndigcols) &#x3D; num_dig(:,activecols);</span><br><span class="line"></span><br><span class="line">[unused,index] &#x3D; sortrows(comp);</span><br><span class="line">if is_descend</span><br><span class="line">    index &#x3D; index(end:-1:1);</span><br><span class="line">end</span><br><span class="line">index &#x3D; reshape(index,size(c));</span><br><span class="line">cs &#x3D; c(index);</span><br><span class="line">end</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://www.tanjialin.cn/posts/12218.html#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
